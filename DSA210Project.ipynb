{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jCuJ02zcAQo5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('annual-working-hours-per-worker.csv')\n",
        "df2 = pd.read_csv('average-years-of-schooling.csv')\n",
        "df3 = pd.read_csv('economic-inequality-gini-index.csv')\n",
        "df4 = pd.read_csv('gdp-per-capita-worldbank.csv')\n",
        "df5 = pd.read_csv('gender-development-index.csv')\n",
        "df6 = pd.read_csv('human-development-index.csv')\n",
        "df7 = pd.read_csv('life-expectancy-hmd-unwpp.csv')\n",
        "df8 = pd.read_csv('marriage-rate-per-1000-inhabitants.csv')\n",
        "df9 = pd.read_csv('share-of-population-urban.csv')\n",
        "df10 = pd.read_csv('unemployment-rate.csv')"
      ],
      "metadata": {
        "id": "ttyM3sPLs1AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After analyzing the data I decided to use these countries which didn't have any major missing data in the datasets. The other countries had a lot of missing data especially in the marriage rates data that is crucial"
      ],
      "metadata": {
        "id": "3jFxq7Hct4cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countries_to_keep = [\n",
        "    \"Argentina\", \"Australia\", \"Austria\", \"Belgium\", \"Bulgaria\",\n",
        "     \"Chile\", , \"Costa Rica\", \"Croatia\", \"Cyprus\", \"Czechia\", \"Denmark\",\n",
        "    \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Iceland\", \"Ireland\",\n",
        "    \"Israel\", \"Italy\", \"Japan\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Mexico\",\n",
        "    \"Netherlands\", \"New Zealand\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\",\n",
        "    \"Slovakia\", \"Slovenia\", \"South Korea\", \"Spain\", \"Sweden\", \"Switzerland\",\n",
        "    \"Turkey\", \"United Kingdom\", \"United States\"\n",
        "]"
      ],
      "metadata": {
        "id": "xGpZOXBJBB-j"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MyAghyEEu5pJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1_cleaned = df1[(df1['Year'] > 2009) & (df1['Year'] < 2016)]\n",
        "df2_cleaned = df1[(df2['Year'] > 2009) & (df2['Year'] < 2016)]\n",
        "df3_cleaned = df1[(df3['Year'] > 2009) & (df3['Year'] < 2016)]\n",
        "df4_cleaned = df1[(df4['Year'] > 2009) & (df4['Year'] < 2016)]\n",
        "df5_cleaned = df1[(df5['Year'] > 2009) & (df5['Year'] < 2016)]\n",
        "df6_cleaned = df1[(df6['Year'] > 2009) & (df6['Year'] < 2016)]\n",
        "df7_cleaned = df1[(df7['Year'] > 2009) & (df7['Year'] < 2016)]\n",
        "df8_cleaned = df1[(df8['Year'] > 2009) & (df8['Year'] < 2016)]\n",
        "df9_cleaned = df1[(df9['Year'] > 2009) & (df9['Year'] < 2016)]\n",
        "df10_cleaned = df1[(df10['Year'] > 2009) & (df10['Year'] < 2016)]"
      ],
      "metadata": {
        "id": "kmyS107-BCM5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df2_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df1_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df1_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df1_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df1_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df1_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df1_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]\n",
        "df1_filtered = df1_cleaned[df1_cleaned['Entity'].isin(countries_to_keep)]"
      ],
      "metadata": {
        "id": "nBhYTGcjBB1z"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df2_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df3_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df4_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df5_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df6_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df7_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df8_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df9_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)\n",
        "df10_filtered.to_csv(\"filtered-daily-mean-income-2011-ppp.csv\", index=False)"
      ],
      "metadata": {
        "id": "OM6DK-keDMcV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "combining files"
      ],
      "metadata": {
        "id": "yBsFUeSMLuBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df1 = pd.read_csv('filtered-annual-working-hours-per-worker.csv')\n",
        "filtered_df2 = pd.read_csv('filtered-average-years-of-schooling.csv')\n",
        "filtered_df3 = pd.read_csv('filtered-daily-mean-income-2011-ppp.csv')\n",
        "filtered_df4 = pd.read_csv('filtered-gdp-per-capita-worldbank.csv')\n",
        "filtered_df5 = pd.read_csv('filtered-gender-development-index.csv')\n",
        "filtered_df6 = pd.read_csv('filtered-human-development-index.csv')\n",
        "filtered_df7 = pd.read_csv('filtered-life-expectancy-hmd-unwpp.csv')\n",
        "filtered_df8 = pd.read_csv('filtered-marriage-rate-per-1000-inhabitants.csv')\n",
        "filtered_df9 = pd.read_csv('filtered-share-of-population-urban.csv')\n",
        "filtered_df10 = pd.read_csv('filtered-unemployment-rate.csv')"
      ],
      "metadata": {
        "id": "e63XOsJNLt1v"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "error accured while merging because of the \"Code\" column so dropping the column because it is not needed"
      ],
      "metadata": {
        "id": "rFwWgLbUN9l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10]:\n",
        "    if \"Code\" in df.columns:\n",
        "        df.drop(columns=[\"Code\"], inplace=True)"
      ],
      "metadata": {
        "id": "Txa5N2r8OBv_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(df1, df2, on=[\"Entity\", \"Year\"], how=\"outer\")\n",
        "merged_df = pd.merge(merged_df, df3, on=[\"Entity\", \"Year\"], how=\"outer\")\n",
        "merged_df = pd.merge(merged_df, df4, on=[\"Entity\", \"Year\"], how=\"outer\")\n",
        "merged_df = pd.merge(merged_df, df5, on=[\"Entity\", \"Year\"], how=\"outer\")\n",
        "merged_df = pd.merge(merged_df, df6, on=[\"Entity\", \"Year\"], how=\"outer\")\n",
        "merged_df = pd.merge(merged_df, df7, on=[\"Entity\", \"Year\"], how=\"outer\")\n",
        "merged_df = pd.merge(merged_df, df8, on=[\"Entity\", \"Year\"], how=\"outer\")\n",
        "merged_df = pd.merge(merged_df, df9, on=[\"Entity\", \"Year\"], how=\"outer\")\n",
        "merged_df = pd.merge(merged_df, df10, on=[\"Entity\", \"Year\"], how=\"outer\")"
      ],
      "metadata": {
        "id": "zpskotYBLtxW"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv('merged_data.csv', index=False)"
      ],
      "metadata": {
        "id": "aWxaPAFhLtum"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPSTfQgZLtqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkOgSAYnLtmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82pIXIX7Lth0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJNKz4msLteA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2rQsrV5ZLtbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "klx-fVDPLtXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgN8TGTcLtU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7ZOjbcXLtQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mp4smQLOLtJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}